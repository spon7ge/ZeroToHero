{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Statistics for Sports Analytics: Days 19-20\n",
    "\n",
    "This notebook compares statistical approaches and builds season-level projection models.\n",
    "\n",
    "**Topics covered:**\n",
    "- Day 19: Bayesian vs Frequentist approaches\n",
    "- Day 20: Simulating full season player stats with uncertainty\n",
    "\n",
    "**Prerequisites:** Basic Python, numpy, matplotlib, Bayes' theorem, Monte Carlo, bootstrapping.\n",
    "\n",
    "Let's import our libraries and set up for reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import beta, norm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Random seed set to 42 for reproducible results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 19: Bayesian vs Frequentist Approaches\n",
    "\n",
    "## Overview of Two Approaches\n",
    "\n",
    "When estimating a player's shooting percentage, we can use two different statistical frameworks.\n",
    "\n",
    "### Frequentist Estimate\n",
    "\n",
    "**Definition:** The sample proportion or sample mean calculated directly from observed data.\n",
    "\n",
    "**For shooting percentage:**\n",
    "- FG% = Total Makes / Total Attempts\n",
    "- Example: 40 makes in 100 attempts → 40% FG%\n",
    "\n",
    "**Key features:**\n",
    "- Uses only the observed data\n",
    "- No prior beliefs incorporated\n",
    "- Uncertainty measured via confidence intervals\n",
    "- Treats the true parameter as fixed but unknown\n",
    "\n",
    "### Bayesian Estimate\n",
    "\n",
    "**Definition:** The posterior mean (or mode/median) after updating prior beliefs with observed data.\n",
    "\n",
    "**For shooting percentage:**\n",
    "- Start with prior: Beta(α₀, β₀)\n",
    "- Update with data: k makes, n-k misses\n",
    "- Posterior: Beta(α₀+k, β₀+n-k)\n",
    "- Posterior mean = (α₀+k) / (α₀+β₀+n)\n",
    "\n",
    "**Key features:**\n",
    "- Incorporates prior beliefs\n",
    "- Updates beliefs with data\n",
    "- Uncertainty represented by posterior distribution\n",
    "- Treats the parameter as having a probability distribution\n",
    "\n",
    "### Simple Example\n",
    "\n",
    "**Scenario:** Player makes 2 out of 5 shots in their first game.\n",
    "\n",
    "**Frequentist:** FG% = 2/5 = 40%\n",
    "\n",
    "**Bayesian (with Beta(20,20) prior):**\n",
    "- Prior mean: 20/40 = 50%\n",
    "- Posterior: Beta(22, 23)\n",
    "- Posterior mean: 22/45 = 48.9%\n",
    "\n",
    "The Bayesian estimate is pulled toward the prior (50%) because we have limited data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Toy Dataset\n",
    "\n",
    "Let's track a player's shooting over their first 15 games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create game-by-game shooting data\n",
    "# Each row: (made_shots, attempted_shots)\n",
    "\n",
    "game_data = [\n",
    "    (5, 12),   # Game 1: 5/12 = 41.7%\n",
    "    (7, 15),   # Game 2: 7/15 = 46.7%\n",
    "    (6, 14),   # Game 3: 6/14 = 42.9%\n",
    "    (8, 16),   # Game 4: 8/16 = 50.0%\n",
    "    (4, 10),   # Game 5: 4/10 = 40.0%\n",
    "    (9, 18),   # Game 6: 9/18 = 50.0%\n",
    "    (7, 13),   # Game 7: 7/13 = 53.8%\n",
    "    (6, 15),   # Game 8: 6/15 = 40.0%\n",
    "    (8, 17),   # Game 9: 8/17 = 47.1%\n",
    "    (10, 20),  # Game 10: 10/20 = 50.0%\n",
    "    (5, 11),   # Game 11: 5/11 = 45.5%\n",
    "    (9, 19),   # Game 12: 9/19 = 47.4%\n",
    "    (7, 14),   # Game 13: 7/14 = 50.0%\n",
    "    (8, 16),   # Game 14: 8/16 = 50.0%\n",
    "    (6, 13),   # Game 15: 6/13 = 46.2%\n",
    "]\n",
    "\n",
    "n_games = len(game_data)\n",
    "\n",
    "print(\"Player Game-by-Game Shooting Data\")\n",
    "print(\"=\"*50)\n",
    "for i, (made, attempted) in enumerate(game_data, 1):\n",
    "    fg_pct = made / attempted\n",
    "    print(f\"Game {i:2d}: {made:2d}/{attempted:2d} = {fg_pct:.1%}\")\n",
    "\n",
    "total_made = sum(m for m, a in game_data)\n",
    "total_attempted = sum(a for m, a in game_data)\n",
    "overall_fg = total_made / total_attempted\n",
    "\n",
    "print(f\"\\nOverall: {total_made}/{total_attempted} = {overall_fg:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist View: Cumulative Sample Proportion\n",
    "\n",
    "The frequentist estimate uses only the data observed so far.\n",
    "\n",
    "After each game, we compute:\n",
    "\n",
    "FG% = (Total makes so far) / (Total attempts so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cumulative frequentist estimates\n",
    "\n",
    "cumulative_makes = []\n",
    "cumulative_attempts = []\n",
    "frequentist_estimates = []\n",
    "\n",
    "running_makes = 0\n",
    "running_attempts = 0\n",
    "\n",
    "for made, attempted in game_data:\n",
    "    running_makes += made\n",
    "    running_attempts += attempted\n",
    "    \n",
    "    cumulative_makes.append(running_makes)\n",
    "    cumulative_attempts.append(running_attempts)\n",
    "    \n",
    "    # Frequentist estimate: sample proportion\n",
    "    freq_estimate = running_makes / running_attempts\n",
    "    frequentist_estimates.append(freq_estimate)\n",
    "\n",
    "print(\"Frequentist Estimates After Each Game:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Game | Cumulative | FG%\")\n",
    "print(\"-\"*60)\n",
    "for i in range(n_games):\n",
    "    print(f\"{i+1:4d} | {cumulative_makes[i]:3d}/{cumulative_attempts[i]:3d}    | {frequentist_estimates[i]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian View: Posterior Mean with Beta Prior\n",
    "\n",
    "The Bayesian approach starts with a prior belief and updates it with each game.\n",
    "\n",
    "**Prior:** Beta(20, 20)\n",
    "- Represents 20 prior \"makes\" and 20 prior \"misses\"\n",
    "- Prior mean = 20/40 = 50%\n",
    "- Equivalent to having seen 40 shots at 50% shooting\n",
    "\n",
    "**Update rule:**\n",
    "- After game with k makes and (n-k) misses\n",
    "- New α = old α + k\n",
    "- New β = old β + (n-k)\n",
    "- Posterior mean = α / (α + β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian estimates with sequential updates\n",
    "\n",
    "# Prior parameters\n",
    "alpha_0 = 20\n",
    "beta_0 = 20\n",
    "prior_mean = alpha_0 / (alpha_0 + beta_0)\n",
    "\n",
    "print(f\"Prior: Beta({alpha_0}, {beta_0})\")\n",
    "print(f\"Prior mean: {prior_mean:.1%}\")\n",
    "print(f\"Prior strength: {alpha_0 + beta_0} pseudo-observations\\n\")\n",
    "\n",
    "# Track posterior parameters\n",
    "current_alpha = alpha_0\n",
    "current_beta = beta_0\n",
    "\n",
    "bayesian_estimates = []\n",
    "alpha_history = []\n",
    "beta_history = []\n",
    "\n",
    "print(\"Bayesian Posterior Estimates After Each Game:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Game | Makes/Att | Posterior      | Post Mean\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, (made, attempted) in enumerate(game_data, 1):\n",
    "    missed = attempted - made\n",
    "    \n",
    "    # Update posterior\n",
    "    current_alpha += made\n",
    "    current_beta += missed\n",
    "    \n",
    "    # Compute posterior mean\n",
    "    posterior_mean = current_alpha / (current_alpha + current_beta)\n",
    "    \n",
    "    # Store results\n",
    "    bayesian_estimates.append(posterior_mean)\n",
    "    alpha_history.append(current_alpha)\n",
    "    beta_history.append(current_beta)\n",
    "    \n",
    "    print(f\"{i:4d} | {made:2d}/{attempted:2d}     | Beta({current_alpha:3d}, {current_beta:3d}) | {posterior_mean:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Compare Frequentist and Bayesian Estimates Over Time\n",
    "\n",
    "Let's visualize how the two approaches differ, especially in early games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both estimates on the same graph\n",
    "\n",
    "game_numbers = np.arange(1, n_games + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Frequentist estimates\n",
    "plt.plot(game_numbers, frequentist_estimates, 'o-', linewidth=2.5, markersize=8,\n",
    "         color='blue', label='Frequentist (Sample FG%)', alpha=0.8)\n",
    "\n",
    "# Bayesian estimates\n",
    "plt.plot(game_numbers, bayesian_estimates, 's-', linewidth=2.5, markersize=8,\n",
    "         color='red', label='Bayesian (Posterior Mean)', alpha=0.8)\n",
    "\n",
    "# Prior mean\n",
    "plt.axhline(y=prior_mean, color='red', linestyle='--', linewidth=2,\n",
    "            alpha=0.5, label=f'Prior Mean ({prior_mean:.1%})')\n",
    "\n",
    "# Final estimate line\n",
    "plt.axhline(y=frequentist_estimates[-1], color='gray', linestyle=':', linewidth=1.5,\n",
    "            alpha=0.5, label=f'Final Estimate ({frequentist_estimates[-1]:.1%})')\n",
    "\n",
    "plt.xlabel('Game Number', fontsize=13)\n",
    "plt.ylabel('Field Goal Percentage', fontsize=13)\n",
    "plt.title('Frequentist vs Bayesian FG% Estimates Over Time', fontsize=15, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='best')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(game_numbers)\n",
    "plt.ylim(0.35, 0.55)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Two Approaches\n",
    "\n",
    "**How each method treats uncertainty:**\n",
    "\n",
    "*Frequentist:*\n",
    "- Point estimate is the sample proportion\n",
    "- Uncertainty measured by confidence intervals\n",
    "- No probability distribution on the parameter itself\n",
    "- Intervals have a frequency interpretation: \"95% of such intervals contain the true value\"\n",
    "\n",
    "*Bayesian:*\n",
    "- Entire posterior distribution represents uncertainty\n",
    "- Can make probability statements about the parameter: \"95% probability FG% is in this range\"\n",
    "- Posterior credible intervals are more intuitive\n",
    "- Uncertainty shrinks as data accumulates (posterior gets narrower)\n",
    "\n",
    "**How prior beliefs influence early games:**\n",
    "\n",
    "*Early games (Games 1-5):*\n",
    "- Frequentist estimate jumps around based purely on observed data\n",
    "- After Game 1: 5/12 = 41.7% (ignores what we know about typical shooters)\n",
    "- Bayesian estimate starts at 50% (prior) and moves gradually toward data\n",
    "- After Game 1: (20+5)/(40+12) = 48.1% (more stable, less reactive)\n",
    "\n",
    "*Why this matters:*\n",
    "- With limited data, frequentist can give extreme estimates\n",
    "- Prior acts as regularization, keeping estimates reasonable\n",
    "- Bayesian approach automatically handles \"small sample\" problem\n",
    "\n",
    "**How both approaches behave with lots of data:**\n",
    "\n",
    "*Late games (Games 10-15):*\n",
    "- Both estimates converge to similar values\n",
    "- After 15 games: Frequentist = 47.1%, Bayesian = 47.3%\n",
    "- Prior influence fades: 40 pseudo-observations vs 215 real observations\n",
    "- Data dominates the prior when sample size is large\n",
    "\n",
    "*Mathematical insight:*\n",
    "\n",
    "Bayesian posterior mean = (α₀ + total_makes) / (α₀ + β₀ + total_attempts)\n",
    "\n",
    "As total_attempts → ∞, this approaches total_makes / total_attempts (frequentist estimate)\n",
    "\n",
    "**Practical implications:**\n",
    "- Early season: Bayesian helps avoid overreacting to hot/cold streaks\n",
    "- Late season: Both methods give similar results\n",
    "- Bayesian naturally balances prior knowledge with new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Visualize Posterior Distribution Evolution\n",
    "\n",
    "Let's see how the posterior distribution changes and uncertainty shrinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot posterior distributions at different points\n",
    "\n",
    "games_to_plot = [1, 5, 10, 15]\n",
    "x = np.linspace(0.3, 0.7, 1000)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, game_num in enumerate(games_to_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    if game_num == 0:\n",
    "        # Prior\n",
    "        alpha_plot = alpha_0\n",
    "        beta_plot = beta_0\n",
    "        title = \"Prior (Before Any Games)\"\n",
    "    else:\n",
    "        # Posterior after game_num games\n",
    "        alpha_plot = alpha_history[game_num - 1]\n",
    "        beta_plot = beta_history[game_num - 1]\n",
    "        title = f\"Posterior After Game {game_num}\"\n",
    "    \n",
    "    # Plot Beta distribution\n",
    "    pdf = beta.pdf(x, alpha_plot, beta_plot)\n",
    "    ax.plot(x, pdf, linewidth=2.5, color='darkblue')\n",
    "    ax.fill_between(x, pdf, alpha=0.3, color='skyblue')\n",
    "    \n",
    "    # Mark the mean\n",
    "    mean_val = alpha_plot / (alpha_plot + beta_plot)\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {mean_val:.1%}')\n",
    "    \n",
    "    # 90% credible interval\n",
    "    ci_lower = beta.ppf(0.05, alpha_plot, beta_plot)\n",
    "    ci_upper = beta.ppf(0.95, alpha_plot, beta_plot)\n",
    "    ax.axvline(ci_lower, color='green', linestyle=':', linewidth=1.5, alpha=0.6)\n",
    "    ax.axvline(ci_upper, color='green', linestyle=':', linewidth=1.5, alpha=0.6,\n",
    "               label=f'90% CI: [{ci_lower:.1%}, {ci_upper:.1%}]')\n",
    "    \n",
    "    ax.set_xlabel('Field Goal Percentage', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title(f'{title}\\nBeta({alpha_plot}, {beta_plot})', fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim(0.3, 0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how:\")\n",
    "print(\"1. The distribution gets narrower (less uncertainty) as games increase\")\n",
    "print(\"2. The mean shifts from the prior toward the data\")\n",
    "print(\"3. The 90% credible interval shrinks significantly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify uncertainty reduction\n",
    "\n",
    "print(\"Uncertainty Reduction Over Time:\")\n",
    "print(\"=\"*70)\n",
    "print(\"Game | Posterior      | Mean  | 90% CI Width\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Prior\n",
    "prior_ci_lower = beta.ppf(0.05, alpha_0, beta_0)\n",
    "prior_ci_upper = beta.ppf(0.95, alpha_0, beta_0)\n",
    "prior_width = prior_ci_upper - prior_ci_lower\n",
    "print(f\"Prior | Beta({alpha_0:3d}, {beta_0:3d}) | {prior_mean:.1%} | {prior_width:.1%}\")\n",
    "\n",
    "# After selected games\n",
    "for game_num in [1, 5, 10, 15]:\n",
    "    alpha_g = alpha_history[game_num - 1]\n",
    "    beta_g = beta_history[game_num - 1]\n",
    "    mean_g = alpha_g / (alpha_g + beta_g)\n",
    "    ci_lower_g = beta.ppf(0.05, alpha_g, beta_g)\n",
    "    ci_upper_g = beta.ppf(0.95, alpha_g, beta_g)\n",
    "    width_g = ci_upper_g - ci_lower_g\n",
    "    \n",
    "    print(f\"{game_num:5d} | Beta({alpha_g:3d}, {beta_g:3d}) | {mean_g:.1%} | {width_g:.1%}\")\n",
    "\n",
    "print(\"\\nThe credible interval width decreases as data accumulates.\")\n",
    "print(\"This shows decreasing uncertainty about the true FG%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 20: Simulate Full Season Player Stats\n",
    "\n",
    "## Parameter Uncertainty\n",
    "\n",
    "When projecting season-level performance, we must account for two types of randomness.\n",
    "\n",
    "### Two Sources of Variability\n",
    "\n",
    "**1. Game-to-game randomness (aleatory uncertainty):**\n",
    "- Even if we knew the player's true mean, individual games vary\n",
    "- A player averaging 25 PPG might score 18 one game and 32 the next\n",
    "- This is inherent randomness in performance\n",
    "- Represented by standard deviation σ_game\n",
    "\n",
    "**2. Uncertainty about the true mean (epistemic uncertainty):**\n",
    "- We don't know the player's \"true\" average with certainty\n",
    "- Based on limited data, the mean could be 24, 25, or 26 PPG\n",
    "- This uncertainty decreases as we observe more games\n",
    "- Represented by posterior distribution of μ\n",
    "\n",
    "### Example: Points Per Game\n",
    "\n",
    "**Scenario:** Player has averaged 24.5 PPG over 20 games with SD of 6 points.\n",
    "\n",
    "**Game-to-game randomness:**\n",
    "- Given true mean μ = 24.5\n",
    "- Game points ~ Normal(24.5, 6)\n",
    "- This variability exists even if we knew μ perfectly\n",
    "\n",
    "**Uncertainty about the mean:**\n",
    "- True μ might not be exactly 24.5\n",
    "- Could be 23, 24.5, or 26 based on our data\n",
    "- Posterior: μ ~ Normal(24.5, τ) where τ depends on sample size\n",
    "- Standard error: τ = σ_game / √n = 6 / √20 ≈ 1.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Modeling for Season Projections\n",
    "\n",
    "**The key insight:** The posterior distribution for the mean can feed into season simulations.\n",
    "\n",
    "**Standard approach (ignoring parameter uncertainty):**\n",
    "1. Estimate mean from data: μ̂ = 24.5\n",
    "2. Simulate season: Each game ~ Normal(24.5, 6)\n",
    "3. Problem: Treats 24.5 as the true mean (overconfident)\n",
    "\n",
    "**Bayesian approach (accounting for parameter uncertainty):**\n",
    "1. Posterior for mean: μ ~ Normal(24.5, 1.34)\n",
    "2. Simulate season:\n",
    "   - First, draw μ_sim from posterior\n",
    "   - Then, simulate games given μ_sim: Each game ~ Normal(μ_sim, 6)\n",
    "3. Benefit: Accounts for uncertainty in the true mean\n",
    "\n",
    "**Result:** Season outcomes have wider variability, reflecting our uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up a Simple Model\n",
    "\n",
    "Let's use a concrete example with made-up data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake season data (20 games so far)\n",
    "\n",
    "np.random.seed(100)\n",
    "n_games_observed = 20\n",
    "true_mean_ppg = 24.5  # Unknown in practice\n",
    "sigma_game = 6.0      # Game-to-game standard deviation\n",
    "\n",
    "# Generate observed game points\n",
    "observed_points = np.random.normal(true_mean_ppg, sigma_game, size=n_games_observed)\n",
    "observed_points = np.maximum(observed_points, 0)  # No negative points\n",
    "\n",
    "# Compute sample statistics\n",
    "sample_mean = np.mean(observed_points)\n",
    "sample_std = np.std(observed_points, ddof=1)\n",
    "\n",
    "print(\"Observed Data (First 20 Games):\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Number of games: {n_games_observed}\")\n",
    "print(f\"Sample mean: {sample_mean:.2f} PPG\")\n",
    "print(f\"Sample std: {sample_std:.2f} points\")\n",
    "print(f\"\\nFirst 10 games: {observed_points[:10].round(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive posterior for the mean\n",
    "# Using Normal prior and Normal likelihood → Normal posterior\n",
    "\n",
    "# For simplicity, assume:\n",
    "# - Game points are Normal(μ, σ_game) with σ_game known\n",
    "# - Weak prior on μ: Normal(25, 10) [very uncertain prior]\n",
    "# - Posterior for μ is Normal(μ_post, τ_post)\n",
    "\n",
    "# Prior parameters\n",
    "prior_mu = 25.0\n",
    "prior_tau = 10.0\n",
    "\n",
    "# Known game-to-game SD (assume we know this)\n",
    "sigma_game_known = 6.0\n",
    "\n",
    "# Posterior parameters (Normal-Normal conjugacy)\n",
    "# Precision (inverse variance)\n",
    "prior_precision = 1 / (prior_tau**2)\n",
    "data_precision = n_games_observed / (sigma_game_known**2)\n",
    "\n",
    "posterior_precision = prior_precision + data_precision\n",
    "posterior_tau = 1 / np.sqrt(posterior_precision)\n",
    "\n",
    "# Posterior mean is weighted average\n",
    "posterior_mu = (prior_precision * prior_mu + data_precision * sample_mean) / posterior_precision\n",
    "\n",
    "# For our case with weak prior, posterior ≈ sample-based estimate\n",
    "# Alternative simpler formula (when prior is weak):\n",
    "# Standard error of mean\n",
    "se_mean = sigma_game_known / np.sqrt(n_games_observed)\n",
    "\n",
    "# Use this as posterior\n",
    "mu_post = sample_mean\n",
    "tau_post = se_mean\n",
    "\n",
    "print(\"Posterior Distribution for Mean PPG:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Posterior: μ ~ Normal({mu_post:.2f}, {tau_post:.2f})\")\n",
    "print(f\"\\nPosterior mean: {mu_post:.2f} PPG\")\n",
    "print(f\"Posterior std (uncertainty about mean): {tau_post:.2f}\")\n",
    "print(f\"\\n95% credible interval for true mean:\")\n",
    "print(f\"  [{mu_post - 1.96*tau_post:.2f}, {mu_post + 1.96*tau_post:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate One Full Season\n",
    "\n",
    "Here's how to generate one possible season outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate one season\n",
    "\n",
    "def simulate_season(n_games_season, mu_post, tau_post, sigma_game):\n",
    "    \"\"\"\n",
    "    Simulate one full season accounting for parameter uncertainty.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_games_season: number of games in the season (e.g., 82)\n",
    "    - mu_post: posterior mean for true average PPG\n",
    "    - tau_post: posterior standard deviation (uncertainty about mean)\n",
    "    - sigma_game: game-to-game standard deviation\n",
    "    \n",
    "    Returns:\n",
    "    - season_avg: average PPG for this simulated season\n",
    "    - season_total: total points for this simulated season\n",
    "    \"\"\"\n",
    "    # Step 1: Draw a value for the true mean from posterior\n",
    "    mu_sim = np.random.normal(mu_post, tau_post)\n",
    "    \n",
    "    # Step 2: Simulate each game given this mean\n",
    "    game_points = np.random.normal(mu_sim, sigma_game, size=n_games_season)\n",
    "    game_points = np.maximum(game_points, 0)  # No negative points\n",
    "    \n",
    "    # Step 3: Compute season statistics\n",
    "    season_avg = np.mean(game_points)\n",
    "    season_total = np.sum(game_points)\n",
    "    \n",
    "    return season_avg, season_total\n",
    "\n",
    "# Test the function\n",
    "np.random.seed(200)\n",
    "test_avg, test_total = simulate_season(82, mu_post, tau_post, sigma_game_known)\n",
    "\n",
    "print(\"Example: One Simulated Season\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Simulated season average: {test_avg:.2f} PPG\")\n",
    "print(f\"Simulated season total: {test_total:.0f} points\")\n",
    "print(\"\\nThis is one possible outcome given our uncertainty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Generate Many Season Outcomes\n",
    "\n",
    "Let's simulate 5,000 possible seasons to understand the distribution of outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate many seasons\n",
    "\n",
    "n_simulations = 5000\n",
    "n_games_season = 82\n",
    "\n",
    "season_averages = []\n",
    "season_totals = []\n",
    "\n",
    "np.random.seed(300)\n",
    "for i in range(n_simulations):\n",
    "    avg, total = simulate_season(n_games_season, mu_post, tau_post, sigma_game_known)\n",
    "    season_averages.append(avg)\n",
    "    season_totals.append(total)\n",
    "\n",
    "season_averages = np.array(season_averages)\n",
    "season_totals = np.array(season_totals)\n",
    "\n",
    "print(f\"Generated {n_simulations} simulated seasons\")\n",
    "print(f\"\\nSummary of Season Averages:\")\n",
    "print(f\"  Mean: {np.mean(season_averages):.2f} PPG\")\n",
    "print(f\"  Std: {np.std(season_averages):.2f}\")\n",
    "print(f\"  Min: {np.min(season_averages):.2f} PPG\")\n",
    "print(f\"  Max: {np.max(season_averages):.2f} PPG\")\n",
    "\n",
    "print(f\"\\nSummary of Season Totals:\")\n",
    "print(f\"  Mean: {np.mean(season_totals):.0f} points\")\n",
    "print(f\"  Std: {np.std(season_totals):.0f}\")\n",
    "print(f\"  Min: {np.min(season_totals):.0f} points\")\n",
    "print(f\"  Max: {np.max(season_totals):.0f} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of simulated outcomes\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Season averages\n",
    "ax1.hist(season_averages, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(25, color='red', linestyle='--', linewidth=2.5, label='25 PPG threshold')\n",
    "ax1.axvline(np.mean(season_averages), color='green', linestyle='-', linewidth=2,\n",
    "            label=f'Mean: {np.mean(season_averages):.2f}')\n",
    "ax1.set_xlabel('Season Average (PPG)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('Distribution of Simulated Season Averages', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Season totals\n",
    "ax2.hist(season_totals, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(2000, color='red', linestyle='--', linewidth=2.5, label='2000 points threshold')\n",
    "ax2.axvline(np.mean(season_totals), color='green', linestyle='-', linewidth=2,\n",
    "            label=f'Mean: {np.mean(season_totals):.0f}')\n",
    "ax2.set_xlabel('Season Total Points', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('Distribution of Simulated Season Totals', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate probabilities from simulations\n",
    "\n",
    "# P(Season average >= 25 PPG)\n",
    "prob_avg_25 = np.mean(season_averages >= 25)\n",
    "\n",
    "# P(Season total >= 2000 points)\n",
    "prob_total_2000 = np.mean(season_totals >= 2000)\n",
    "\n",
    "print(\"Estimated Probabilities from Simulation:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"P(Avg PPG >= 25): {prob_avg_25:.3f} ({prob_avg_25*100:.1f}%)\")\n",
    "print(f\"  Out of {n_simulations} seasons, {int(prob_avg_25*n_simulations)} had avg >= 25\")\n",
    "\n",
    "print(f\"\\nP(Total >= 2000 pts): {prob_total_2000:.3f} ({prob_total_2000*100:.1f}%)\")\n",
    "print(f\"  Out of {n_simulations} seasons, {int(prob_total_2000*n_simulations)} had total >= 2000\")\n",
    "\n",
    "# Additional percentiles\n",
    "print(f\"\\nPercentiles of Season Average:\")\n",
    "print(f\"  10th: {np.percentile(season_averages, 10):.2f} PPG\")\n",
    "print(f\"  25th: {np.percentile(season_averages, 25):.2f} PPG\")\n",
    "print(f\"  50th: {np.percentile(season_averages, 50):.2f} PPG\")\n",
    "print(f\"  75th: {np.percentile(season_averages, 75):.2f} PPG\")\n",
    "print(f\"  90th: {np.percentile(season_averages, 90):.2f} PPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Uncertainty in True Mean Affects Season Outcomes\n",
    "\n",
    "**Key observations:**\n",
    "\n",
    "**1. Wider distribution than naive simulation:**\n",
    "\n",
    "If we simulated with a fixed mean (ignoring uncertainty):\n",
    "- SD of season averages ≈ σ_game / √82 = 6 / 9.1 ≈ 0.66\n",
    "\n",
    "With parameter uncertainty:\n",
    "- SD of season averages ≈ √(τ_post² + σ_game²/82)\n",
    "- SD ≈ √(1.34² + 0.66²) ≈ 1.50\n",
    "\n",
    "The distribution is about 2× wider when we account for uncertainty!\n",
    "\n",
    "**2. Two sources of variability:**\n",
    "\n",
    "*Parameter uncertainty (τ_post = 1.34):*\n",
    "- Different seasons might have different \"true\" averages\n",
    "- One season the true mean might be 23.5, another might be 25.5\n",
    "- This persists across the entire season\n",
    "\n",
    "*Game-to-game randomness (σ_game = 6):*\n",
    "- Even with fixed true mean, games vary\n",
    "- But averages over 82 games: variation is σ/√82 ≈ 0.66\n",
    "\n",
    "**3. Parameter uncertainty dominates for season averages:**\n",
    "- τ_post = 1.34 >> σ_game/√82 = 0.66\n",
    "- Most variation in season average comes from not knowing true mean\n",
    "- More historical data → smaller τ_post → tighter projections\n",
    "\n",
    "**Practical implications:**\n",
    "- Early career players: Large τ_post → wide range of season outcomes\n",
    "- Established veterans: Small τ_post → narrow range (more predictable)\n",
    "- Projections should reflect our uncertainty level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: With vs Without Parameter Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to simulation with fixed mean (no parameter uncertainty)\n",
    "\n",
    "np.random.seed(400)\n",
    "n_sim_comparison = 5000\n",
    "\n",
    "# Simulation 1: With parameter uncertainty (what we did)\n",
    "season_avg_with_uncertainty = season_averages\n",
    "\n",
    "# Simulation 2: Fixed mean (ignoring uncertainty)\n",
    "season_avg_fixed_mean = []\n",
    "for i in range(n_sim_comparison):\n",
    "    # Use sample mean as if it were the true mean\n",
    "    game_pts = np.random.normal(mu_post, sigma_game_known, size=n_games_season)\n",
    "    game_pts = np.maximum(game_pts, 0)\n",
    "    season_avg_fixed_mean.append(np.mean(game_pts))\n",
    "\n",
    "season_avg_fixed_mean = np.array(season_avg_fixed_mean)\n",
    "\n",
    "# Compare\n",
    "print(\"Comparison: Parameter Uncertainty vs Fixed Mean\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nWith parameter uncertainty:\")\n",
    "print(f\"  Mean: {np.mean(season_avg_with_uncertainty):.2f} PPG\")\n",
    "print(f\"  Std: {np.std(season_avg_with_uncertainty):.2f}\")\n",
    "print(f\"  95% interval: [{np.percentile(season_avg_with_uncertainty, 2.5):.2f}, \"\n",
    "      f\"{np.percentile(season_avg_with_uncertainty, 97.5):.2f}]\")\n",
    "\n",
    "print(f\"\\nFixed mean (no uncertainty):\")\n",
    "print(f\"  Mean: {np.mean(season_avg_fixed_mean):.2f} PPG\")\n",
    "print(f\"  Std: {np.std(season_avg_fixed_mean):.2f}\")\n",
    "print(f\"  95% interval: [{np.percentile(season_avg_fixed_mean, 2.5):.2f}, \"\n",
    "      f\"{np.percentile(season_avg_fixed_mean, 97.5):.2f}]\")\n",
    "\n",
    "print(f\"\\nRatio of standard deviations: \"\n",
    "      f\"{np.std(season_avg_with_uncertainty) / np.std(season_avg_fixed_mean):.2f}\")\n",
    "print(\"\\nParameter uncertainty adds substantial additional variability!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the comparison\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(season_avg_fixed_mean, bins=40, alpha=0.5, color='blue', \n",
    "         label='Fixed mean (no parameter uncertainty)', edgecolor='black')\n",
    "plt.hist(season_avg_with_uncertainty, bins=40, alpha=0.5, color='red',\n",
    "         label='With parameter uncertainty', edgecolor='black')\n",
    "\n",
    "plt.axvline(mu_post, color='black', linestyle='--', linewidth=2,\n",
    "            label=f'Estimated mean: {mu_post:.2f}')\n",
    "\n",
    "plt.xlabel('Season Average (PPG)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Impact of Parameter Uncertainty on Season Projections', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The red distribution (with uncertainty) is wider.\")\n",
    "print(\"This better reflects the true range of possible season outcomes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How This Supports Projections and Risk Analysis\n",
    "\n",
    "**1. More realistic uncertainty quantification:**\n",
    "- Traditional projections often underestimate uncertainty\n",
    "- Accounting for parameter uncertainty gives wider, more honest ranges\n",
    "- Better for decision-making under uncertainty\n",
    "\n",
    "**2. Risk assessment:**\n",
    "- \"What's the probability the player fails to average 25 PPG?\"\n",
    "- With uncertainty: ~59% chance of < 25 PPG\n",
    "- Without uncertainty: ~41% chance (underestimates risk)\n",
    "\n",
    "**3. Contract negotiations:**\n",
    "- Player wants contract based on optimistic projection\n",
    "- Team needs to account for downside risk\n",
    "- Simulation shows full distribution of plausible outcomes\n",
    "\n",
    "**4. Roster construction:**\n",
    "- Need to hit certain point totals for playoffs\n",
    "- Can estimate: P(combined team total > threshold)\n",
    "- Accounts for correlation and individual uncertainties\n",
    "\n",
    "**5. Early vs late season:**\n",
    "- Early season: Large τ_post → wide projections\n",
    "- Late season: Small τ_post → narrow projections\n",
    "- Automatically adjusts as more data arrives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Compare Two Players\n",
    "\n",
    "Simulate seasons for two players and estimate the probability one outscores the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two players\n",
    "\n",
    "# Player A: More data, more certain\n",
    "player_a_mu_post = 24.5\n",
    "player_a_tau_post = 1.0   # Lower uncertainty\n",
    "player_a_sigma_game = 6.0\n",
    "\n",
    "# Player B: Less data, less certain, slightly higher estimate\n",
    "player_b_mu_post = 25.0\n",
    "player_b_tau_post = 2.5   # Higher uncertainty (less data)\n",
    "player_b_sigma_game = 7.0\n",
    "\n",
    "print(\"Two Player Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Player A: μ ~ N({player_a_mu_post:.1f}, {player_a_tau_post:.1f}), σ_game = {player_a_sigma_game}\")\n",
    "print(f\"Player B: μ ~ N({player_b_mu_post:.1f}, {player_b_tau_post:.1f}), σ_game = {player_b_sigma_game}\")\n",
    "print(\"\\nPlayer B has slightly higher mean but much more uncertainty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate seasons for both players\n",
    "\n",
    "np.random.seed(500)\n",
    "n_sim_compare = 10000\n",
    "\n",
    "player_a_totals = []\n",
    "player_b_totals = []\n",
    "\n",
    "for i in range(n_sim_compare):\n",
    "    # Player A\n",
    "    _, total_a = simulate_season(82, player_a_mu_post, player_a_tau_post, player_a_sigma_game)\n",
    "    player_a_totals.append(total_a)\n",
    "    \n",
    "    # Player B\n",
    "    _, total_b = simulate_season(82, player_b_mu_post, player_b_tau_post, player_b_sigma_game)\n",
    "    player_b_totals.append(total_b)\n",
    "\n",
    "player_a_totals = np.array(player_a_totals)\n",
    "player_b_totals = np.array(player_b_totals)\n",
    "\n",
    "# Count how often each player has more total points\n",
    "player_a_wins = np.sum(player_a_totals > player_b_totals)\n",
    "player_b_wins = np.sum(player_b_totals > player_a_totals)\n",
    "ties = n_sim_compare - player_a_wins - player_b_wins\n",
    "\n",
    "prob_a_wins = player_a_wins / n_sim_compare\n",
    "prob_b_wins = player_b_wins / n_sim_compare\n",
    "\n",
    "print(\"Season Total Points Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Player A mean total: {np.mean(player_a_totals):.0f} points\")\n",
    "print(f\"Player B mean total: {np.mean(player_b_totals):.0f} points\")\n",
    "\n",
    "print(f\"\\nP(Player A total > Player B total): {prob_a_wins:.3f} ({prob_a_wins*100:.1f}%)\")\n",
    "print(f\"P(Player B total > Player A total): {prob_b_wins:.3f} ({prob_b_wins*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDespite Player B having a higher estimated mean,\")\n",
    "print(f\"Player A has a {prob_a_wins*100:.0f}% chance of outscoring Player B\")\n",
    "print(f\"because Player A's performance is more certain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distributions\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.hist(player_a_totals, bins=50, alpha=0.5, color='blue', \n",
    "         label=f'Player A (μ={player_a_mu_post:.1f}, τ={player_a_tau_post:.1f})', \n",
    "         edgecolor='black', density=True)\n",
    "plt.hist(player_b_totals, bins=50, alpha=0.5, color='red',\n",
    "         label=f'Player B (μ={player_b_mu_post:.1f}, τ={player_b_tau_post:.1f})',\n",
    "         edgecolor='black', density=True)\n",
    "\n",
    "plt.axvline(np.mean(player_a_totals), color='blue', linestyle='--', linewidth=2)\n",
    "plt.axvline(np.mean(player_b_totals), color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.xlabel('Season Total Points', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('Comparing Two Players: Season Total Points Distribution', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Player B's distribution is wider due to greater uncertainty.\")\n",
    "print(\"More data on Player A leads to more consistent projections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: Bayesian vs Frequentist and Season Simulations\n",
    "\n",
    "## Bayesian vs Frequentist for Shooting Percentage\n",
    "\n",
    "**Frequentist approach:**\n",
    "- Estimate: Sample proportion (makes / attempts)\n",
    "- Uses only observed data\n",
    "- Can be unstable with limited data\n",
    "- Confidence intervals based on sampling distribution\n",
    "\n",
    "**Bayesian approach:**\n",
    "- Estimate: Posterior mean from Beta distribution\n",
    "- Combines prior beliefs with data\n",
    "- More stable with limited data (prior acts as regularization)\n",
    "- Credible intervals from posterior distribution\n",
    "\n",
    "**Key differences:**\n",
    "- Early games: Bayesian stays closer to prior, frequentist jumps around\n",
    "- Late games: Both converge to similar values\n",
    "- Bayesian automatically handles small sample problems\n",
    "- Frequentist treats parameter as fixed; Bayesian as random\n",
    "\n",
    "---\n",
    "\n",
    "## Posterior Updating Game by Game\n",
    "\n",
    "**The update process:**\n",
    "1. Start with prior Beta(α₀, β₀)\n",
    "2. After each game: Add makes to α, add misses to β\n",
    "3. New posterior becomes prior for next game\n",
    "4. Posterior mean = α / (α + β)\n",
    "\n",
    "**How beliefs change:**\n",
    "- Game 1: Posterior close to prior (limited data)\n",
    "- Game 5: Posterior between prior and data\n",
    "- Game 15: Posterior dominated by data\n",
    "\n",
    "**Uncertainty evolution:**\n",
    "- Posterior distribution gets narrower over time\n",
    "- Credible intervals shrink as data accumulates\n",
    "- More games → more certainty about true FG%\n",
    "\n",
    "---\n",
    "\n",
    "## Simulating Full Seasons with Uncertainty\n",
    "\n",
    "**Two types of uncertainty:**\n",
    "\n",
    "*Game-to-game randomness:*\n",
    "- Individual games vary even with known mean\n",
    "- Represented by σ_game\n",
    "- Averages out over 82 games\n",
    "\n",
    "*Parameter uncertainty:*\n",
    "- Don't know the true mean exactly\n",
    "- Represented by posterior distribution for μ\n",
    "- Doesn't average out (systematic across season)\n",
    "\n",
    "**Simulation procedure:**\n",
    "1. Draw true mean from posterior: μ_sim ~ N(μ_post, τ_post)\n",
    "2. Simulate games given that mean: Points ~ N(μ_sim, σ_game)\n",
    "3. Compute season average and total\n",
    "4. Repeat thousands of times\n",
    "\n",
    "**Result:** Distribution of season outcomes accounting for both uncertainties\n",
    "\n",
    "---\n",
    "\n",
    "## Applications to Season Performance Questions\n",
    "\n",
    "**Probability estimation:**\n",
    "- \"What's P(player averages ≥ 25 PPG)?\"\n",
    "- Count simulated seasons meeting criterion\n",
    "- Accounts for all sources of uncertainty\n",
    "\n",
    "**Comparison:**\n",
    "- \"Which player will score more this season?\"\n",
    "- Simulate both, compare outcomes\n",
    "- More certain player (lower τ) has advantage\n",
    "\n",
    "**Projections:**\n",
    "- Not just point estimate (e.g., 24.5 PPG)\n",
    "- Full distribution showing range of plausible outcomes\n",
    "- Different percentiles for optimistic/pessimistic scenarios\n",
    "\n",
    "**Risk assessment:**\n",
    "- Understand downside risk\n",
    "- Account for uncertainty in decision-making\n",
    "- More realistic than treating estimates as certain\n",
    "\n",
    "**Why this matters:**\n",
    "- Traditional projections: Often too confident (narrow ranges)\n",
    "- Bayesian simulations: Honest about uncertainty\n",
    "- Better for high-stakes decisions (contracts, trades, draft)\n",
    "- Naturally updates as season progresses (more data → less uncertainty)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Bayesian and frequentist converge with data** but differ importantly early on\n",
    "\n",
    "2. **Prior beliefs matter when data is limited** but fade with accumulation\n",
    "\n",
    "3. **Parameter uncertainty is often larger** than game-to-game randomness for season projections\n",
    "\n",
    "4. **Simulations accounting for uncertainty** give more realistic projections\n",
    "\n",
    "5. **These methods support better decision-making** by quantifying the full range of plausible outcomes\n",
    "\n",
    "**The Bayesian framework provides a principled way to:**\n",
    "- Incorporate prior knowledge\n",
    "- Update beliefs with data\n",
    "- Propagate uncertainty through predictions\n",
    "- Make probabilistic statements about future performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
